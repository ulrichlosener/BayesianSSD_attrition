---
title: "Tutorial for Bayesian Sample Size Determination with Empirical Longitudinal Data"
subtitle: "Introduction to the BayeSSD package"
author: "Ulrich Lösener <br>  Utrecht University <br> Department of Methodology and Statistics"
date: "4-6-2025"
output: 
  prettydoc::html_pretty:
    theme: cayman
    toc: true
---

***

This tutorial illustrates how to use the open-access R package `BayeSSD` for Bayesian sample size determination (see Lösener & Moerbeek, 2025 for a description of an earlier version of this software). The starting point is the data of an existing empirical study which informs our (fictional) future longitudinal experiment with three treatment conditions and expected attrition. Our goal is to replicate a previous longitudinal experiment using Bayesian hypothesis evaluation and to make an informed choice about the number of individuals in the sample. Note that the model estimation is maximum likelihood, while the hypothesis about the frequentist estimates is evaluated in a Bayesian way. We would like to achieve a Bayesian power level of at least .8, given that our design and expected attrition is identical to the previous study.

The data comes from the study "How Can We Increase Privacy Protection Behavior? A Longitudinal Experiment Testing Three Intervention Strategies" by Boerman, Strycharz and Smit (2023). The data are available on the [Open Science Framework](https://osf.io/f4zrs/files/osfstorage) (OSF). Note that for illustrative purposes, we only focus on a subset of the hypotheses and treatment conditions that were investigated in this paper. 

Each participant's perceived susceptibility to the threat of online data collection, usage, and sharing measured three times (at baseline, two weeks after, and two months after). The participants were randomly allocated to three strategy training conditions: a) no strategy, b) addressing the threat, and c) training effective behavior. Our research hypothesis states that both interventions lead to a steeper decline in perceived threat over time compared to the no strategy condition. Furthermore, we hypothesize that the decline in both intervention conditions is equal. Thus, the research hypothesis is: $\mathcal{H}_1:\beta_a < \beta_b=\beta_c$, where $\beta$ refers to the coefficient of interaction between `time` and `condition`. Note that this hypothesis is constructed purely for illustrative purposes and does not reflect the author's content-related expectations.

The steps of this tutorial are as follows: First, we load and clean the data. Next, we inspect some plots in order to determine that fitting a multilevel model to this data is indeed sensible. After that, we fit the multilevel model. Next, we extract the estimates of effects sizes along with the (co-)variance components necessary to inform our sample size determination (SSD) procedure. Then, we specify the pattern of attrition we expect in our replication study based on the reported attrition rates in Boerman et al. (2023). Finally, we execute the SSD using the `BayeSSD` package. 

# Data preparation

### Load data

First, we load the data. These are openly available on [OSF](https://osf.io/f4zrs/files/osfstorage) and are fully anonymous.

```{r read data}
dat <- read.csv("waveall_final.csv")
```

### Convert from wide to long

Next, we have to convert the data frame into the long format in order to be able to fit a multilevel regression model using the `lme4` package. We also convert some variable types to make them more suitable for model fitting. To do this, we load the `dplyr` and the `tidyr` package for more convenient data restructuring.

```{r wide to long, message=F}
# install packages if needed
if (!require("dplyr")) {install.packages("dplyr")}
if (!require("tidyr")) {install.packages("tidyr")}

# call their libraries
library(dplyr)
library(tidyr)

dat_raw_long <- dat %>%
  select(-notnew_W1, -deelsnew_W1) %>%  # drop problematic character columns
  # ensure there's an "id" column for participants
  mutate(id = row_number()) %>%  
  pivot_longer(
    cols = matches("_W[1-3]r?$"),  # matches _W1, _W2, _W3, _W1r, _W2r, _W3r
    names_to = c("variable", "wave", "suffix"),  
    names_pattern = "(.*?)_W([1-3])(r)?",  # breaks into (variable)_W(wave)(optional r)
    values_to = "value",
    values_drop_na = TRUE
  ) %>%
  mutate(
    wave = as.integer(wave),  # convert wave to integer
    # combine variable name and suffix (if it exists)
    variable = ifelse(!is.na(suffix), paste0(variable, "_", suffix), variable)
  ) %>%
  select(-suffix) %>%  # remove the temporary suffix column
  pivot_wider(
    names_from = "variable",  
    values_from = "value"
  )

# rename 'conditie_' to 'condition'
names(dat_raw_long)[names(dat_raw_long) == "conditie_"] <- "condition"
```

### Complement and subset data

In the variable `condition`, we see that always the last value for each participant in missing, so we need to fill those in. As participants did not switch conditions, this will simply be equal to the previous value for condition within that person. 

```{r fill in condition}
# fill in missing condition values for last wave
dat_raw_long_full <- dat_raw_long %>%
  group_by(id) %>%
  fill(condition, .direction = "updown") %>%
  ungroup()
```


Next, we create a data frame with only those variables relevant to the analysis. Also, we will only be considering participants in conditions a), b) and c) (coded as 0-2). We also need to recode the `condition` variable as a factor instead of numeric.

```{r subset data}
# subset data: only variables that are used in models & only conditions 0-2
dat_long <- dat_raw_long_full[(dat_raw_long_full$condition==0 | dat_raw_long_full$condition==1 | dat_raw_long_full$condition==2), c("id", "wave", "condition", "susc_")]
# rename conditions to a), b), c)
dat_long$condition[dat_long$condition==0] <- "a"
dat_long$condition[dat_long$condition==1] <- "b"
dat_long$condition[dat_long$condition==2] <- "c"
```

Now, we add rows for the missing observations such that each participant has three rows with observations, even if some of them are NA.
```{r add NA}
# add rows with NA for missing timepoints
dat_long_final <- dat_long %>%
  # first complete all id-wave combinations
  complete(id, wave = 1:3) %>%
  # then fill the condition variable with previous values from the same id
  group_by(id) %>%
  fill(condition, .direction = "downup") %>%  # fills both directions to handle edge cases
  ungroup()
```

### Add `time` variable

As the last step in the data cleaning process, we need to recode the `wave` variable into a new `time` variable with the actual time points (0, 2, 8). We inspect the first couple of rows of the new data frame to make sure it is formatted correctly.

```{r recode wave}
# if wave is one, recode to 0, if wave is 3, recode to 8
dat_final <- dat_long_final %>% 
              mutate(time = ifelse(wave == 1, 0, 
                                   ifelse(wave == 3, 8, wave)))
# inspect first couple of rows
head(dat_final)
```



Now, our dataset is ready for model fitting. Before we fit the model, however, we first make some plots to show that the data indeed has a multilevel structure. 

# Plots

### Multilevel structure

We inspect the data via lineplots using the `ggplot2` package. First, we illustrate the multilevel structure of the data on a random subset of 25 participants, as showing all 1000 participant's lines would not be illustrative. We thus plot the `susceptibility` of each of these 25 individuals over time separately in a facet plot. The black solid line shows the raw values per point in time while the dotted red line represents the linear trend of that person. Note that some individuals have missing values due to dropping out. 

```{r plot lines per person, message=F, warning=F}
# install if needed
if (!require("ggplot2")) {install.packages("ggplot2")}

# call the library
library(ggplot2)

# randomly select 25 individuals to showcase
set.seed(123) # So the sample is the same each time we run the code
sample_ids <- sample(unique(dat_final$id), 25)

# filter the data to only include those IDs
dat_sample <- dat_final %>%
  filter(id %in% sample_ids)

# create the faceted plot
ggplot(dat_sample, aes(x = time, y = susc_)) +
  geom_point() +                   # add points for the actual observations
  geom_line() +                    # connect the points with lines
  geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") + # add individual LM fit
  facet_wrap(~ id, ncol = 5) +     # create a 4x4 grid of panels
  labs(title = "Linear trends over time of a random sample of 25 individuals",
       x = "time",
       y = "susceptibility") +
  theme_minimal()
```

We can see that there is considerable variability in both the initial scores and the linear trend over time between individuals. Some individuals start with a higher score, others with a lower score. Some individuals show a positive trend, others a negative one, and yet others do not change over time at all with respect to the outcome. Hence, a multilevel regression model with random intercepts and slopes seems like the appropriate choice. 

### Differential growth per condition

Next, we plot the linear trends over time per condition.

```{r plots, warning=F}
# plot regression lines for each condition for time on susceptibility
ggplot(data  = dat_final,
       aes(x = time, y = susc_, group=condition, color=condition)) +
  geom_point(size = 1.2,
             position  = "jitter",
             aes(color = condition)) + # "jitter" adds some random noise to differentiate the points
  geom_smooth(method   = lm,
              formula  = "y ~ x",
              se       = FALSE) +
  theme_minimal() +
  ylim(c(4,7)) +
  scale_x_continuous(breaks = c(0, 2, 8)) +
  labs(title = "Susceptibility over time per condition", y = "susceptibility", color = "condition")
```

From the plots we can gather that there is a slight ceiling effect and that there seem to be some small differences in the linear growth between the three conditions. 

# Multilevel regression model

In this step, we fit the multilevel regression model to the data using the `lme4` package. We do this in order to obtain estimates necessary to run the SSD algorithm. Alternatively, if no data are available, these estimates can be obtained from experts in the respective field of research.

### Fit the model

First, we fit the multilevel regression model to the data. The predictors are `time`, `condition` and their interaction `time:condition`. Intercepts and slopes for time are allowed to vary per person as indicated by the random part of the regression equation`(1 + time | id)`.

```{r fit MLM, message=F, warning=F}
# install if needed
if (!require("lme4")) {install.packages("lme4")}
# call the library
library(lme4)

# model for susceptibility with condition and time as well as their interaction as predictors
mlm_susc <- lmer(susc_ ~ 1 + time + condition + time:condition + (1 + time | id), dat_final, REML = F)
summ_mlm_susc <- summary(mlm_susc)
summ_mlm_susc
```

From the model output, we gather that in the first condition a), the perceived susceptibility of individuals increases slightly over time, as indicated by the estimate for `time` which is equal to 0.005. We also see that in the conditions b) and c), participants growth is smaller compared to the reference condition a), as indicated by the coefficients for `time:conditionb` and `time:conditionc` which are equal to -0.013 and -0.011, respectively. Note that for the purpose of this tutorial, we ignore the singular model fit, which is likely caused by the near-zero estimate of the slope variance. 

### Extract estimates

Next, we extract all the (co-)variance components needed for our sample size determination. Specifically, the intercept variance, the slope variance, their covariance, and the residual variance.

```{r extract estimates}
# Intercept variance
var_intercept <- summ_mlm_susc$varcor$id[1,1]

# Slope variance
var_slope <- summ_mlm_susc$varcor$id[2,2]

# Covariance between random intercept and random slope
cov_int_slope <- summ_mlm_susc$varcor$id[1,2]

# Residual variance
var_resid <- sigma(mlm_susc)^2

```

### Calculate effect sizes

The effect size found in the previous study serves as an estimate for the effect size we expect to find. It is defined as the ratio between the regression coefficient and the square root of the slope variance $\delta = \frac{\beta}{\sqrt{\sigma^2_{u1}}}$ (Raudenbush & Liu, 2001). This means that we can derive the effect sizes from the regression coefficients and the slope variance as follows:

```{r calc effect size}
# beta_cond1 <- mlm_sev@beta[2] # the coefficient of interaction between time and condition for the reference condition (cond1) is the coefficient for "time"
beta_cond_a <- mlm_susc@beta[2] # the coefficient of interaction between time and condition for the reference condition (cond1) is the coefficient for "time"
# beta_cond2 <- mlm_sev@beta[5]
beta_cond_b <- mlm_susc@beta[5]

# beta_cond3 <- mlm_sev@beta[6]
beta_cond_c <- mlm_susc@beta[6]


# calculate effect sizes for each treatment condition
delta_cond_a <- beta_cond_a / sqrt(var_slope)
delta_cond_b <- beta_cond_b / sqrt(var_slope)
delta_cond_c <- beta_cond_c / sqrt(var_slope)

```

For an illustrative overview of the influence of the multilevel model parameters on the growth curves, please visit the [ShinyApp](https://losener.shinyapps.io/MLM_input/) developed for this purpose.

# Time points and attrition

The $n=3$ timepoints are at baseline ($t_1=0$), two weeks later ($t_2=2$) and two months later ($t_3=8$), with $t$ denoting the number of weeks since the start of the study. At each of the three measurement occasions, there are $N_1=1000$, $N_2=799$ and $N_3=465$ individuals remaining in the sample (Boerman et al., 2024). This corresponds to a dropout proportion of .21 at $t_2$ and of .535 at $t_2$.

The plot below shows the proportion of dropout at each measurement occasion.

```{r missing plot, message=F,warning=F}
# install scales package if needed
if (!require("scales")) {install.packages("scales")}

# create data of timepoints and remaining individuals
timepoints <- c(0, 2, 8)
proportions <- c(1, 0.799, 0.465)

# create a data frame in long format for plotting
df <- data.frame(
  x = rep(factor(timepoints), each = 2),  
  group = rep(c("remaining", "dropped out"), times = length(timepoints)),  
  value = c(rbind(proportions, 1 - proportions))) 

# plot
ggplot(df, aes(x = x, y = value, fill = group)) +
  geom_col(position = "stack") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  labs(
    x = "Time elapsed in weeks",
    y = "Proportion of individuals",
    fill = "Status"
  ) +
  theme_minimal()
```

For an extensive overview of the available survival functions that can be used for modelling attrition in the `BayeSSD` package, please visit the [ShinyApp](https://losener.shinyapps.io/attrition-survival/) developed for this purpose.

# Using the `BayeSSD` package

### Package installation

Now that we obtained all the estimates necessary to perform the Bayesian Sample Size Determination, we need to install the package `BayeSSD` from GitHub. If you are prompted to update any package that are needed for this, please do so.

```{r BayeSSD Package, message=F, warning=F, eval=F}
if (!require("devtools")) {install.packages("devtools")}

devtools::install_github("ulrichlosener/BayeSSD", force=TRUE)
library(BayeSSD)
```

### Arguments to the function

The following table provides an overview of all the arguments to the function and their default values. 

```{r table arguments, echo=F, message=F, warning=F}
if (!require("knitr")) {install.packages("knitr")}

tab <- data.frame(
  Argument = c("eta", "attrition", "params", "BFthres", "PMPthres", "eff.sizes", "m", "t.points", "log", "var.u0", "var.u1", "var.e", "cov", "fraction", "sensitivity", "hypothesis", "method", "N.min", "N.max", "tol", "seed"),
  Type = c("numeric","string","list/vector","numeric","numeric","numeric","numeric","vector","logical","numeric","numeric","numeric","numeric","numeric","logical","string","string","numeric","numeric","numeric","numeric"),
  Description = c("the desired power level","if FALSE, no attrition is simulated. Otherwise, input determines the survival function(s) used.","parameter values passed to the survival function. Single vector if the same attrition pattern applies to all treatment conditions. Otherwise list of vectors for each pattern. First entry is omega, second gamma and third (if applicable) kappa.","The threshold a BF must exceed in order to be considered convincing evidence","The threshold a PMP must exceed in order to be considered convincing evidence","delta, the expected standardized effect size(s)","the number of datasets to be simulated in each iteration","the time points of the measurement occasions, equal and unequal spacing possible","use log-linear growth?","the intercept variance","the slope variance","the residual variance","the covariance between intercept and slope variance","J, fraction of information to specify the prior: b=J/N","execute sensitivity analysis for different values (1, 2, 3) for fraction?","Either a single hypothesis or a list of hypotheses with the research hypothesis of interest in first place. Treatment conditions are referred to as 'a, b, c, ...,'","The method of hypothesis evaluating: 'bfc' refers to the BF versus the complement hypothesis, 'bf' to the BF of the first versus the second hypothesis in 'hypothesis' and 'pmp' to the posterior model probability in the set of all hypotheses including the complement hypothesis.","The minimal sample size to be considered","The maximal sample size to be considered", "tolerance of deviation from desired power. Higher values may speed up performance.","set a seed for reproducibility"),
  Default =c("0.8","'weibull'","c(0.5, 1)","3","0.9","c(0, 0.5, 0.8)","1000","c(0,1,2,3,4)","FALSE","0.03","0.1","0.02","0","1","FALSE","'a<b<c'","'bfc'","30","1000","0.001","NULL")
)
knitr::kable(tab, caption = "Arguments to the BayeSSD function")

```

### Performing Bayesian SSD

Now, we can run the simulation-based Bayesian SSD with the `BayeSSD` command and pass all the ingredients to the appropriate arguments. Remember that we strive for a power level of $\eta=.8$ and our research hypothesis is $\mathcal{H}_1:\beta_a < \beta_b; \beta_b=\beta_c$. We are planning on evaluating this hypothesis against the complement hypothesis $\mathcal{H}_c$ which covers all parameter orderings not included in our research hypothesis $\mathcal{H}_1$. Because we are planning on running a confirmatory rather than an exploratory study, we set the threshold for a convincing Bayes Factor $BF_{1c}$ to 10. Because we are using linear and not log-linear growth, we set `log=F` (default). For reliable results, we set `m=10000`, meaning that 10,000 datasets are simulated and evaluated in each iteration. Increasing `m` increases the precision as well as the computing time of the algorithm. We also set a seed for reproducibility, as some parts of the simulation rely on stochastic processes. For more information on the arguments of the `BayeSSD` function, run `?BayeSSD`.    

```{r SSD, cache=TRUE}
BayeSSD(eta        = 0.8,
        hypothesis = "a>b & b=c",
        attrition  = "nonparametric",
        params     = c(1, 0.799, 0.465),
        m          = 10000,
        t.points   = c(0,2,8),
        var.u0     = var_intercept,
        var.u1     = var_slope,
        var.e      = var_resid,
        cov        = cov_int_slope,
        eff.sizes  = c(delta_cond_a, delta_cond_b, delta_cond_c),
        BFthres    = 10,
        method     = "bfc",
        seed       = 123)
```

The output informs us of the number of the current iteration, the sample size (total number of subjects) that is currently being evaluated, the power that this sample size corresponds to, the time elapsed since the start, and a rough estimate of the remaining computing time. It also tells us that in iteration 3, less than 0.1% of the models in the simulation had to be simplified by constraining the random effects to be uncorrelated. Without this simplification, it is not possible to estimate the model. However, as this proportion is very small, this simplification is negligible.

After 6 iterations, the algorithm found the sample size corresponding to $\eta$, our desired power level. Thus, we need to sample a total amount of $N=195$ individuals in our fictional replication study in order to have a probability of .80 to obtain a $BF_{1c} \geq 10$ in favor of our research hypothesis, given that it is indeed true. 

***

If you have questions or comments about this Markdown document or about the `BayeSSD` Package, please contact me under u.c.losener@uu.nl.


# References

Boerman, S. C., Strycharz, J., & Smit, E. G. (2024). How can we increase privacy protection behavior? A longitudinal experiment testing three intervention strategies. Communication research, 51(2), 115-145.

Lösener, U., & Moerbeek, M. (2025). Bayesian sample size determination for longitudinal intervention studies with linear and log-linear growth. Behavior Research Methods, 57(9), 239.

Raudenbush, S. W., & Liu, X. F. (2001). Effects of study duration, frequency of observation, and sample size on power in studies of group differences in polynomial change. Psychological methods, 6(4), 387.
