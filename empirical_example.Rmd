---
title: "Tutorial for Bayesian Sample Size Determination with Empirical Longitudinal Data"
subtitle: "Introduction to the BayesSSD package"
author: "Ulrich Lösener <br>  Utrecht University <br> Department of Methodology and Statistics"
date: "4-6-2025"
output: 
  prettydoc::html_pretty:
    theme: cayman
    toc: true
---

***

This tutorial illustrates how to use the open-access R package `BayesSSD` for Bayesian sample size determination (SSD; see Lösener & Moerbeek, 2025 for a description of an earlier version of this software). The starting point is the data of an existing empirical study, which informs the SSD for our (fictional) longitudinal experiment with three treatment conditions and expected attrition. Our goal is to replicate a previous longitudinal experiment using Bayesian hypothesis evaluation and to make an informed choice about the number of individuals in the sample. Note that the model *estimation* is maximum likelihood, while the hypothesis about the frequentist estimates is evaluated in a Bayesian way. We would like to achieve a Bayesian power level of at least $\eta = .8$, given that our design and expected attrition is identical to the previous study.

The data come from the study "How Can We Increase Privacy Protection Behavior? A Longitudinal Experiment Testing Three Intervention Strategies" by Boerman, Strycharz and Smit (2023). The data are fully anonymous and openly available on the [Open Science Framework](https://osf.io/f4zrs/overview) (OSF). Note that for illustrative purposes, we only focus on a subset of treatment conditions and outcome variables that were investigated in the original study. 

Each participant's perceived susceptibility to the threat of online data collection, usage, and sharing was measured three times (at baseline, two weeks after, and two months after). The participants were randomly allocated to four strategy training conditions: a) *no strategy (control)*, b) *addressing the severity of the threat*, c) *training effective privacy protection behavior*, and d) *acknowledging and combating privacy fatigue*. The dependent variable was *perceived susceptibility of infringement of privacy*. Our research hypothesis states that all three interventions (b, c and d) lead to a steeper decline in perceived susceptibility over time compared to the control condition (a). Furthermore, we hypothesize that the decline in intervention conditions b) and c) is equal while the decline in condition d) is the steepest. Thus, the research hypothesis is: $\mathcal{H}_1:\beta_a > \beta_b = \beta_c > \beta_d$, where $\beta$ refers to the coefficient of interaction between `time` and the respective `condition` in the multilevel regression model. The research hypothesis will be evaluated against its complement $\mathcal{H}_c$, which covers all parameter orderings left uncovered by $\mathcal{H}_1$. Note that the research hypothesis is constructed purely for illustrative purposes and may not reflect the author's content-related expectations nor be of any conceptual value.

The steps of this tutorial are as follows: First, we load and clean the data. Next, we inspect some plots in order to determine that fitting a multilevel model to this data is indeed sensible. After that, we fit the multilevel model. Next, we extract the estimates of effects sizes along with the (co-)variance components necessary to inform our sample size determination (SSD) procedure. Then, we specify the pattern of attrition we expect in our replication study based on the reported attrition rates in Boerman et al. (2023). Finally, we execute the SSD using the `BayesSSD` package. 

# Data preparation

### Load data

First, we load the data. These are openly available on [OSF](https://osf.io/f4zrs/overview) and are fully anonymous. Note that to be able to execute the code below, the data must be stored in the same location as the working directory of the R session.

```{r read data}
dat_raw <- read.csv("waveall_final.csv")
```

### Subset data, convert from wide to long

Next, we have to convert the data frame into the long format in order to be able to fit a multilevel regression model using the `lme4` package. We also convert some variable types to make them more suitable for model fitting. To do this, we load the `dplyr` and the `tidyr` package for more convenient data restructuring.

We first create a data frame with only those variables relevant to the analysis. Also, we will only be considering participants in conditions a), b), c) and d) (coded as 0-3). We also need to rename the values in the `condition` variable.

In the variable `condition`, we see that always the last value for each participant in missing, so we need to fill those in. As participants did not switch conditions, this will simply be equal to the previous value for condition within that person. 


```{r wide to long, message=F}
# install packages if needed
if (!require("dplyr")) {install.packages("dplyr")}
if (!require("tidyr")) {install.packages("tidyr")}

# call their libraries
library(dplyr)
library(tidyr)

# select only relevant variables
relevant_vars <- c("susc_W1", "susc_W2", "susc_W3", "conditie_W1", "conditie_W2") 
dat_raw_subset <- dat_raw[,relevant_vars] # subset dataset

# convert from wide to long format
dat_raw_long <- dat_raw_subset %>%
  mutate(id = row_number()) %>%
  pivot_longer(
    cols = -id,
    names_to = c(".value", "wave"),
    names_pattern = "(.*)_W(\\d+)"
  )

# rename variables for clarity
names(dat_raw_long)[names(dat_raw_long) == "conditie"] <- "condition"
names(dat_raw_long)[names(dat_raw_long) == "susc"] <- "susceptibility"

# fill in missing condition values for last wave and only select individuals in conditions 0-3
dat_long <- dat_raw_long %>%
  group_by(id) %>%
  fill(condition, .direction = "updown") %>%
  ungroup() %>%
  filter(condition <= 3)

# rename conditions to a), b), c), d)
dat_long$condition[dat_long$condition==0] <- "a"
dat_long$condition[dat_long$condition==1] <- "b"
dat_long$condition[dat_long$condition==2] <- "c"
dat_long$condition[dat_long$condition==3] <- "d"
```

### Add `time` variable

As the last step in the data cleaning process, we need to recode the `wave` variable into a new `time` variable with the actual time points (0, 2, 8). We inspect the first couple of rows of the new data frame to make sure it is formatted correctly.

```{r recode wave}
# if wave is one, recode to 0, if wave is 2, it stays the same, if wave is 3, recode to 8
dat <- dat_long %>% 
          mutate(time = ifelse(wave == 1, 0, ifelse(wave == 3, 8, wave)))
          
dat$time <- as.numeric(dat$time) # make time numeric

head(dat) # inspect first couple of rows
```

Now, our dataset is ready for model fitting. Before we fit the model, however, we first make some plots to show that the data indeed has a multilevel structure. 

# Plots

### Multilevel structure

We inspect the data via lineplots using the `ggplot2` package. First, we illustrate the multilevel structure of the data on a random subset of 25 participants, as showing all 1000 participant's lines would not be practical We thus plot the `susceptibility` of each of these 25 individuals over time separately in a facet plot. The black solid line shows the raw values per point in time while the dotted red line represents the linear trend of that person. Note that some individuals have missing values due to dropping out. 

```{r plot lines per person, message=F, warning=F}
# install if needed
if (!require("ggplot2")) {install.packages("ggplot2")}

# randomly select 25 individuals to showcase
set.seed(123) # So the sample is the same each time we run the code
sample_ids <- sample(unique(dat$id), 25)

# filter the data to only include those IDs
dat_sample <- dat %>%
  filter(id %in% sample_ids)

# create the faceted plot
ggplot2::ggplot(dat_sample, aes(x = time, y = susceptibility)) +
                  geom_point() +                   # add points for the actual observations
                  geom_line() +                    # connect the points with lines
                  geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") + # add individual LM fit
                  facet_wrap(~ id, ncol = 5) +     # create a 4x4 grid of panels
                  labs(title = "Linear trends over time of a random sample of 25 individuals") +
                  theme_minimal()
```

We can see that there is considerable variability in both the initial scores and the linear trend over time between individuals. Some individuals start with a higher score, others with a lower score. Some individuals show a positive trend, others a negative one, and yet others do not change over time at all with respect to the outcome. Hence, a multilevel regression model with random intercepts and slopes seems like an appropriate choice. 

### Differential growth per condition

Next, we plot the linear trends over time per condition.

```{r plots, warning=F}
# plot regression lines for each condition for time on susceptibility
ggplot2::ggplot(data  = dat,
                 aes(x = time, y = susceptibility, group=condition, color=condition)) +
            geom_point(size = 1.2,
                       position  = "jitter",
                       aes(color = condition)) + # "jitter" adds some random noise to differentiate the points
            geom_smooth(method   = lm,
                        formula  = "y ~ x",
                        se       = FALSE) +
            theme_minimal() +
            ylim(c(4,7)) +
            scale_x_continuous(breaks = c(0, 2, 8)) +
            labs(title = "Susceptibility over time per condition", color = "condition")
```

From the plots we can gather that there is a slight ceiling effect and that there seem to be some small differences in the linear growth between the three conditions. In the following, we systematically analyze how the growth rates differ between conditions and use the estimates to inform our SSD procedure. 

# Multilevel regression model

In this step, we fit the multilevel regression model to the data using the `lme4` package. We do this in order to obtain estimates necessary to run the SSD algorithm. Alternatively, if no data are available, these estimates can be obtained by consulting experts in the respective field of research.

### Fit the model

First, we fit the multilevel regression model to the data. The predictors are `time`, `condition` and their interaction `time:condition`. Intercepts and slopes for time are allowed to vary per person as indicated by the random part of the regression equation`(1 + time | id)`.

```{r fit MLM, message=F, warning=F}
# install if needed
if (!require("lme4")) {install.packages("lme4")}
# call the library
library(lme4)

# model for susceptibility with condition and time as well as their interaction as predictors
mlm <- lmer(susceptibility ~ 1 + time + condition + time:condition + (1 + time | id), dat, REML = F)
summ_mlm <- summary(mlm)

# inspect model output
summ_mlm
```

From the model output, we gather that in the first condition a), the perceived susceptibility of individuals increases slightly over time, as indicated by the estimate for `time` which is equal to 0.005. We also see that in the conditions b), c) and d), the change over time is smaller compared to the reference condition a), as indicated by the coefficients for `time:conditionb`, `time:conditionc` ad `time:conditiond`, which are equal to -0.014, -0.011 and -0.028, respectively. Note that for the purpose of this tutorial, we ignore the singular model fit, which is likely caused by the near-zero estimate of the slope variance.

### Extract estimates

Next, we extract all the (co-)variance components needed for the SSD. Specifically, the intercept variance, the slope variance, their covariance, and the residual variance.

```{r extract estimates}
# intercept variance
var_intercept <- summ_mlm$varcor$id[1,1]

# slope variance
var_slope <- summ_mlm$varcor$id[2,2]

# covariance between random intercept and random slope
cov_int_slope <- summ_mlm$varcor$id[1,2]

# residual variance
var_resid <- sigma(mlm)^2
```

### Calculate effect sizes

The effect size found in the previous study serves as an estimate for the effect size we expect to find. It is defined as the ratio between the regression coefficient and the square root of the slope variance $\delta = \frac{\beta}{\sqrt{\sigma^2_{u1}}}$ (Raudenbush & Liu, 2001). This means that we can derive the effect sizes from the regression coefficients and the slope variance as follows:

```{r calc effect size}
# the coefficient of interaction between time and condition for the reference condition (a) is the coefficient for "time"
beta_cond_a <- mlm@beta[2] 
beta_cond_b <- mlm@beta[6]
beta_cond_c <- mlm@beta[7]
beta_cond_d <- mlm@beta[8]

# calculate effect sizes for each treatment condition according to Raudenbush & Liu (2001)
delta_cond_a <- beta_cond_a / sqrt(var_slope)
delta_cond_b <- beta_cond_b / sqrt(var_slope)
delta_cond_c <- beta_cond_c / sqrt(var_slope)
delta_cond_d <- beta_cond_d / sqrt(var_slope)
```

For an illustrative overview of the influence of the multilevel model parameters on the growth curves, please visit the [ShinyApp](https://losener.shinyapps.io/MLM_input/) developed for this purpose.

# Time points and attrition

The $n=3$ timepoints are at baseline ($t_1=0$), two weeks later ($t_2=2$) and two months later ($t_3=8$), with $t$ denoting the number of weeks since the start of the study. At each of the three measurement occasions, there are $N_1=1000$, $N_2=799$ and $N_3=465$ individuals remaining in the sample (Boerman et al., 2024). This corresponds to a remaining proportion of .799 at $t_2$ and of .465 at $t_2$.

The plot below shows the proportion of dropout at each measurement occasion.

```{r missing plot, message=F,warning=F}
# install scales package if needed
if (!require("scales")) {install.packages("scales")}

# create data of timepoints and remaining individuals
timepoints <- c(0, 2, 8)
proportions <- c(1, 0.799, 0.465)

# create a data frame in long format for plotting
df <- data.frame(
  x = rep(factor(timepoints), each = 2),  
  group = rep(c("remaining", "dropped out"), times = length(timepoints)),  
  value = c(rbind(proportions, 1 - proportions))) 

# plot
ggplot(df, aes(x = x, y = value, fill = group)) +
  geom_col(position = "stack") +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  labs(
    x = "Time elapsed in weeks",
    y = "Proportion of individuals remaining",
    fill = "Status"
  ) +
  theme_minimal()
```

For an extensive overview of the available survival functions that can be used for modelling attrition in the `BayesSSD` package, please visit the [ShinyApp](https://losener.shinyapps.io/attrition-survival/) developed for this purpose.

# Using the `BayesSSD` package

### Package installation

Now that we obtained all the estimates necessary to perform the Bayesian Sample Size Determination, we need to install the package `BayesSSD` from GitHub. If you are prompted to update any package that are needed for this, please do so.

```{r BayesSSD Package, message=F, warning=F, results=F}
if (!require("devtools")) {install.packages("devtools")}

devtools::install_github("ulrichlosener/BayesSSD", force=TRUE)
library(BayesSSD)
```

### Arguments to the `BayesSSD` function

The following table provides an overview of all the arguments to the function `SSD_longit` and their default values. 

```{r table arguments, echo=F, message=F, warning=F}
if (!require("knitr")) {install.packages("knitr")}

tab <- data.frame(
  Argument = c("eta", "attrition", "params", "BFthres", "PMPthres", "eff.sizes", "m", "t.points", "log", "var.u0", "var.u1", "var.e", "cov", "sensitivity", "hypothesis", "method", "N.min", "N.max", "tol", "seed"),
  Type = c("numeric","string","list/vector","numeric","numeric","numeric","numeric","vector","logical","numeric","numeric","numeric","numeric","logical","string","string","numeric","numeric","numeric","numeric"),
  Description = c("the desired power level","if FALSE, no attrition is simulated. Otherwise, input determines the survival function(s) used.","parameter values passed to the survival function. Single vector if the same attrition pattern applies to all treatment conditions. Otherwise list of vectors for each pattern. First entry is omega, second gamma and third (if applicable) kappa.","The threshold a BF must exceed in order to be considered convincing evidence","The threshold a PMP must exceed in order to be considered convincing evidence","delta, the expected standardized effect size(s)","the number of datasets to be simulated in each iteration","the time points of the measurement occasions, equal and unequal spacing possible","use log-linear growth?","the intercept variance","the slope variance","the residual variance","the covariance between intercept and slope variance","execute sensitivity analysis for different values (1, 2, 3) for fraction?","Either a single hypothesis or a list of hypotheses with the research hypothesis of interest in first place. Treatment conditions are referred to as 'a, b, c, ...,'","The method of hypothesis evaluating: 'bfc' refers to the BF versus the complement hypothesis, 'bf' to the BF of the first versus the second hypothesis in 'hypothesis' and 'pmp' to the posterior model probability in the set of all hypotheses including the complement hypothesis.","The minimal sample size to be considered","The maximal sample size to be considered", "tolerance of deviation from desired power. Higher values may speed up performance.","set a seed for reproducibility"),
  Default =c("0.8","'weibull'","c(0.5, 1)","3","0.9","c(0, 0.5, 0.8)","1000","c(0,1,2,3,4)","FALSE","0.03","0.1","0.02","0","FALSE","'a<b<c'","'bfc'","30","1000","0.001","NULL")
)
knitr::kable(tab, caption = "Arguments to the BayesSSD function")

```

### Performing Bayesian SSD

Now, we can run the simulation-based Bayesian SSD with the `BayesSSD` command and pass all the ingredients to the appropriate arguments. Remember that we strive for a power level of $\eta=.8$ and our research hypothesis is $\mathcal{H}_1:\beta_a > \beta_b=\beta_c>\beta_d$. We are planning on evaluating this hypothesis against the complement hypothesis $\mathcal{H}_c$ which covers all parameter orderings not included in our research hypothesis $\mathcal{H}_1$. Because we are planning on running a exploratory rather than a confirmatory study, we set the threshold for a convincing Bayes Factor $BF_{1c}$ to 3 in order not to miss any small but relevant effects. Because our hypothesis includes an equality constraint (=), the $BF_{1c}$ will be influenced by the fraction of information used to inform the default prior ($b$). The fraction $b$ is set by default to $b=p/N_{eff}$, where $p$ is the number of independent constraints in the hypothesis (in this case, 3). In order to assess the sensitivity of $BF_{1c}$ to $b$, we carry out a sensitivity analysis by setting `sensitivity=TRUE`, in which the SSD is performed for $b_1=p/N_{eff}$, $b_2=(p+1)/N_{eff}$ and $b_3=(p+2)/N_{eff}$, as recommended by Gu et al. (2018) and Hoijtink (2019). On a cautionary note, this sensitivity analysis should *not* be used to determine the $b$ for which the least individuals are needed to achieve the desired power level. The choice of $b$ should be made solely based on methodological deliberation (see Gu et al., 2018 for guidance).

For reliable results, we set `m=10000`, meaning that 10,000 datasets are simulated and evaluated in each iteration. Increasing `m` increases the precision as well as the computing time of the algorithm. We also set a seed for reproducibility, as some parts of the simulation rely on stochastic processes. For more information on the arguments of the `BayesSSD` function, run `?BayesSSD` or see the table above.    

```{r SSD, cache=TRUE}
SSD_longit(eta         = 0.8,
           hypothesis  = "a > b = c > d",
           attrition   = "nonparametric",
           params      = c(1, 0.799, 0.465),
           m           = 10000,
           t.points    = c(0,2,8),
           var.u0      = var_intercept,
           var.u1      = var_slope,
           var.e       = var_resid,
           cov         = cov_int_slope,
           eff.sizes   = c(delta_cond_a, delta_cond_b, delta_cond_c, delta_cond_d),
           BFthres     = 3,
           method      = "bfc",
           sensitivity = TRUE,
           seed        = 123
)
```

The output informs us of the number of the current iteration, the sample size (total number of subjects) that is currently being evaluated, the power that this sample size corresponds to, the time elapsed since the start, and a rough estimate of the remaining computing time. It also tells us that in some iterations, less than 0.1% of the models in the simulation had to be simplified by constraining the random effects to be uncorrelated. Without this model simplification, it is not possible to estimate the model due to a small number of observations. However, as this proportion is very small, this simplification is negligible.

Because we set `sensitivity=TRUE`, the SSD is performed three times in the context of a sensitivity analysis for the $b$ fraction. The output shows that when using $b_1$, the total number of individuals needed for a power of at least $\eta=.8$ is $N=132$ (33 per condition), when using $b_2$, the total number of individuals needed is $N=176$ (44 per condition), and when using $b_3$, the total number of individuals needed is $N=240$ (60 per condition).

***

# References

Boerman, S. C., Strycharz, J., & Smit, E. G. (2024). How can we increase privacy protection behavior? A longitudinal experiment testing three intervention strategies. *Communication research, 51*(2), 115-145.

Gu, X., Mulder, J., & Hoijtink, H. (2018). Approximated adjusted fractional Bayes factors: A general method for testing informative hypotheses. *British Journal of Mathematical and Statistical Psychology, 71*(2), 229-261.

Hoijtink, H., Mulder, J., Van Lissa, C., & Gu, X. (2019). A tutorial on testing hypotheses using the Bayes factor. *Psychological methods, 24*(5), 539.

Lösener, U., & Moerbeek, M. (2025). Bayesian sample size determination for longitudinal intervention studies with linear and log-linear growth. *Behavior Research Methods, 57*(9), 239.

Raudenbush, S. W., & Liu, X. F. (2001). Effects of study duration, frequency of observation, and sample size on power in studies of group differences in polynomial change. *Psychological methods, 6*(4), 387.

*** 

If you have questions or comments about this Markdown document or about the `BayesSSD` Package, please contact me under u.c.losener@uu.nl.

***